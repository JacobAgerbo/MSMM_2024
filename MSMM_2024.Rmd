---
title: "MSMM_2024"
author: "Jacob Agerbo Rasmussen"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load deps}
if (!requireNamespace("BiocManager", quietly = TRUE)) {
install.packages("BiocManager")
    }

# List of libraries to be loaded
libs <- c("tidyverse", "readxl", "ggpubr", "Hmisc", "hilldiv", "reshape2")

# Check if each library is installed, if not, install quietly using BiocManager
for (lib in libs) {
if (!requireNamespace(lib, quietly = TRUE)) {
    BiocManager::install(lib, dependencies = TRUE)}
library(lib, character.only = TRUE)
    }

suppressPackageStartupMessages({
  library(tidyverse)
  library(readxl)
  library(ggpubr)
  library(Hmisc)
  library(hilldiv)
  library(reshape2)
})

rm(lib,libs)
```

#Fatty acid profiles as phenotype
So in this data, we have given some salmon blue mussels (either 0 % or 13.1 %). Lets see how this affect their fatty acid composition.

```{r Look at FA profile}
FA <- read_excel("Fatty_Acids.xlsx")
FA %>%
mutate(Treatment = as.factor(Treatment)) %>%
select(Treatment, contains("%")) %>%
reshape2::melt() %>%
ggboxplot(x = "Treatment",
            y = "value",
            fill = "Treatment") +
facet_wrap(~variable, scales = "free_y") +
stat_compare_means(label.x = 1.5, label = "p.signif") +
scale_fill_manual(values = c("#eb4034", "#28478f")) +
theme(legend.position = "none") +
ylab("Sum-Normalised Abundace")
```


```{r get some data}
md <- read_excel("metadata.xlsx") # Lets load metadata into Rstudio
MT <- read.csv("MetaTranscriptome.csv", # Load MT data
           row.names = 1)
```

```{r get KO in MT which are also in MG}
# Set the directory path where your data frames are located
directory_path <- "KOs_across_MAGs/"

# Get a list of file names in the directory
file_names <- list.files(path = directory_path, pattern = "\\.txt$", full.names = TRUE)

names <- sub(directory_path, "", basename(file_names))
names <- sub("-gene_calls.txt", "", basename(names))
# Read all data frames from the files into a list of data frames
dfs_list <- lapply(file_names, function(file) {
read.csv(file, sep = "\t")
})

names(dfs_list) <- names
# Subtract the column from each dataframe in the list
# Subtract the KOfam column from each data frame
modified_dataframes <- lapply(dfs_list, function(df) {
df <- df$KOfam..ACCESSION.
return(df)
})

KO_df <- plyr::ldply(modified_dataframes, data.frame) %>%
rename(MAG = ".id", koFAM = "X..i..") %>%
group_by(MAG) %>%
distinct(koFAM) %>%
mutate(Presence = ifelse(koFAM == "", 0, 1)) %>%
pivot_wider(names_from = MAG, id_cols = koFAM, values_from = Presence) %>%
filter(koFAM != "") %>%
column_to_rownames(var = "koFAM") %>%
mutate_all(~ if_else(is.na(.), 0, .))

KO_df <- KO_df %>%
rownames_to_column(var = "koFAM") %>%
filter(koFAM %in% rownames(MT))

MT <- MT %>%
rownames_to_column(var = "koFAM") %>%
filter(koFAM %in% KO_df$koFAM)
```

#Get functional information from koFAMs related to meta-transcriptome and metagenome
Since we exported gene coverages and functional information from each gene from anvio, we can now use it to link to metatranscriptome.

We start with loading the functional information and the gene coverage, which will be summed together by koFAM ids, so we have the koFAM coverage (multiple genes can lead to a koFAM accession in a metagenome).

```{r get functional informations for KOs}
# Get functional information
FUNCTIONS <- read.csv("FUNCTIONS.txt", sep = "\t") %>%
    # Filter rows where source is "KOfam"
    filter(source == "KOfam")

# Get gene coverage
gene_cov <- read.csv("FUNCTIONS-GENE-COVERAGES.txt", sep = "\t") %>%
    # Filter rows where key is in FUNCTIONS$gene_callers_id
    filter(key %in% FUNCTIONS$gene_callers_id) %>%
    # Rename the "key" column to "gene_callers_id"
    rename(gene_callers_id = "key") %>%
    # Merge gene_cov with FUNCTIONS on "gene_callers_id"
    full_join(FUNCTIONS, by = "gene_callers_id") %>%
    # Select columns containing "ERR"
    select(accession, contains("ERR"))

# Make koFAM coverage
KO_cov <- gene_cov %>%
    reshape2::melt() %>%
    dplyr::group_by(accession, variable) %>%
    summarise(value = sum(value)) %>%
    pivot_wider(names_from = variable, id_cols = accession) %>%
    filter(accession %in% KO_df$koFAM)
```
```{r get funcitonal info ready for nodes}
# Read the FUNCTIONS.txt file into the KO_FUNCTIONS dataframe
KO_FUNCTIONS <- read.csv("FUNCTIONS.txt", sep = "\t") %>%
    # Filter rows where source is "KOfam"
    filter(source == "KOfam") %>%
    # Filter rows where accession is in KO_cov$accession
    filter(accession %in% KO_cov$accession) %>%
    # Rename columns
    rename("ID" = gene_callers_id,
            "KOfam" = function.) %>%
    # Select specific columns
    select(ID, accession, KOfam)

# Read the FUNCTIONS.txt file into the COG_CAT dataframe
COG_CAT <- read.csv("FUNCTIONS.txt", sep = "\t") %>%
    # Filter rows where gene_callers_id is in KO_FUNCTIONS$ID
    filter(gene_callers_id %in% KO_FUNCTIONS$ID) %>%
    # Filter rows where source is "COG20_CATEGORY"
    filter(source == "COG20_CATEGORY") %>%
    # Rename columns
    rename("ID" = gene_callers_id) %>%
    # Select specific columns
    select(ID, function.) %>%
    # Rename the "function." column to "COG_CATEGORY"
    rename("COG_CATEGORY" = function.) %>%
    # Remove "!!!" and anything after it from the COG_CATEGORY values
    mutate(COG_CATEGORY = str_remove(COG_CATEGORY, "!!!.*")) %>%
    # Keep only distinct rows based on ID
    distinct(ID, .keep_all = TRUE)

# Merge the KO_FUNCTIONS and COG_CAT dataframes on the "ID" column
FUNCTIONS <- KO_FUNCTIONS %>%
    full_join(COG_CAT, by = "ID") %>%
    # Keep only distinct rows based on "accession"
    distinct(accession, .keep_all = TRUE) %>%
    # Drop the "ID" column
    select(-ID)

```

Now we make the dataframes for fatty acids, metagenome, metatranscriptome ready for a co-association.

```{r make data ready for coassociation}
# Transforming MT data
MT_df <- MT %>%
dplyr::mutate(koFAM = paste("MT_", koFAM, sep ="")) %>%  # Add "MT_" prefix to koFAM values
column_to_rownames(var = "koFAM")  # Set koFAM as row names
colnames(MT_df) <- md$Genome  # Set column names to Genome values from md

# Transforming KO_cov data
KO_cov_df <- KO_cov %>%
dplyr::mutate(accession = paste("MG_", accession, sep ="")) %>%  # Add "MG_" prefix to accession values
rename("koFAM" = accession) %>%  # Rename accession to koFAM
column_to_rownames(var = "koFAM")  # Set koFAM as row names

# Loading MG data from file
MG_df <- read.csv("SUMMARY/bins_across_samples/mean_coverage_Q2Q3.txt", sep = "\t") %>%  # Read data from file
column_to_rownames(var = "bins")  # Set bins as row names

# Transforming FA data
FA_df <- FA %>%
mutate(Sample = md$Genome) %>%  # Add Sample column with Genome values from md
select(Sample, contains("%")) %>%  # Select columns containing "%"
reshape2::melt() %>%  # Reshape data
pivot_wider(names_from = Sample, id_cols = variable) %>%  # Pivot data
column_to_rownames(var = "variable")  # Set variable as row names
```

Data columns are a bit messy, so we reorder them and sum-normalise the columns before making the co-association.

```{r normalise data for coassociation}
# Define the desired order of columns based on MG_df
desired_order <- colnames(MG_df)

# Reorder columns in FA_df to match the desired order and apply total sum scaling (tss).
FA_df <- FA_df %>%
select(all_of(desired_order)) %>%  # Select columns based on desired order
hilldiv::tss()  # Apply hilldiv::tss() function

# Reorder columns in MT_df to match the desired order and apply hilldiv::tss()
MT_df <- MT_df %>%
select(all_of(desired_order)) %>%  # Select columns based on desired order
hilldiv::tss()  # Apply hilldiv::tss() function

# Reorder columns in KO_cov_df to match the desired order and apply hilldiv::tss()
KO_cov_df <- KO_cov_df %>%
select(all_of(desired_order)) %>%  # Select columns based on desired order
hilldiv::tss()  # Apply hilldiv::tss() function

# Apply hilldiv::tss() function to MG_df
MG_df <- MG_df %>%
select(all_of(desired_order)) %>%  # Select columns based on desired order
hilldiv::tss()  # Apply hilldiv::tss() 
```
Combine data 

```{r combine dataframes}
# Combine Fatty Acids, koFAM coverage, Metatranscriptome, and MAG abundances using rbind
cor_df <- rbind(FA_df, KO_cov_df, MT_df, MG_df)
```

Now we make a correlation of all features across the 20 samples (totally undersampled, i know).

```{r correlate features dataframes}
# Calculate the correlation matrix of the transposed cor_df using rcorr
cor_FA_x_MG_x_MT <- rcorr(t(cor_df))

# Default settings for rcorr:
# - type: "pearson" for Pearson correlation
# - use: "pairwise.complete.obs" for pairwise complete observations
# - ncp: "NULL" for default
# - sig.level: "0.05" for significance level
# - show: "complete" to show complete output
# - digits: "2" for number of digits after the decimal point
```

Now we will use the Pearson Rho coefficient for out network.

```{r get coefficients}
# Reshape the correlation matrix data and rename the columns
df <- cor_FA_x_MG_x_MT$r %>%  # Extract the correlation matrix from cor_FA_x_MG_x_MT and reshape
reshape2::melt()  # Reshape the data into long format
colnames(df) <- c("Source", "Target", "Pearson_Rho")  # Rename the columns
```

To be conservative and minimise false positive, we will apply a bonferonni correction for each correlation, using a home-made function rcorr_padjust.

```{r adjust p values}
# Function to adjust p-values in an rcorr object
rcorr_padjust <- function(x, method = "BH") {
stopifnot(class(x) == "rcorr")  # Check if input is an rcorr object
x$P[upper.tri(x$P)] <- p.adjust(x$P[upper.tri(x$P)], method = method)  # Adjust p-values in the upper triangle of the P matrix
x$P[lower.tri(x$P)] <- p.adjust(x$P[lower.tri(x$P)], method = method)  # Adjust p-values in the lower triangle of the P matrix
return(x)  # Return the modified rcorr object
}

# Adjust p-values in the correlation matrix and filter based on adjusted p-values
df_p <- rcorr_padjust(cor_FA_x_MG_x_MT, method = "bonferroni")  # Adjust p-values in cor_FA_x_MG_x_MT using Bonferroni method
df_adj_p <- df_p$P %>%  # Extract adjusted p-values
reshape2::melt()  # Reshape the data into long format
colnames(df_adj_p) <- c("Source", "Target", "adj_p_value")  # Rename the columns as Source, Target, and adj_p_value

# Add adjusted p-values to the original dataframe and filter based on conditions
df <- df %>%  # Original dataframe
mutate(adj_p_value = df_adj_p$adj_p_value) %>%  # Add adjusted p-values
filter(Source != Target,  # Filter out rows where Source is equal to Target
        adj_p_value < 0.05)  # Filter out rows with adjusted p-value less than 0.05

```

Last thing is to generate our node table, so we have some information for our nodes in the network.

```{r generate nodes and edges}
# Create MG_FUNCTIONs and MT_FUNCTIONs dataframes
MG_FUNCTIONs <- FUNCTIONS %>%  # Subset of FUNCTIONS dataframe for MG
dplyr::mutate(accession = paste("MG_", accession, sep = ""))  # Add "MG_" prefix to accession values
MT_FUNCTIONs <- FUNCTIONS %>%  # Subset of FUNCTIONS dataframe for MT
dplyr::mutate(accession = paste("MT_", accession, sep = ""))  # Add "MT_" prefix to accession values

# Combine MG_FUNCTIONs and MT_FUNCTIONs, rename column
FUNCTIONS <- rbind(MG_FUNCTIONs, MT_FUNCTIONs) %>%  # Combine MG_FUNCTIONs and MT_FUNCTIONs
rename("Source" = accession)  # Rename the column to "Source"

# Create nodes dataframe based on Source values
nodes <- df %>%  # Original dataframe df
select(Source) %>%  # Select Source column
mutate(Type = case_when(  # Create Type column based on conditions
    str_detect(Source, "MGY") ~ "MAG",  # MAG type if Source contains "MGY"
    str_detect(Source, "MG_") ~ "KO_coverage",  # KO_coverage type if Source contains "MG_"
    str_detect(Source, "MT_") ~ "KO_Expression",  # KO_Expression type if Source contains "MT_"
    str_detect(Source, "%") ~ "Fatty Acid",  # Fatty Acid type if Source contains "%"
    TRUE ~ "Other"  # Other type for all other cases
)) %>%  
distinct(Source, .keep_all = TRUE) %>%  # Keep unique Source values
full_join(FUNCTIONS, by = "Source") %>%  # Join with FUNCTIONS dataframe
filter(!is.na(Type)) %>%  # Filter out rows with NA Type
rename("Id" = Source)  # Rename Source column to Id
```

```{r export}
# Save the dataframe df to a CSV file for Gephi
write.csv(df, "correlation_network_for_gephi.csv", row.names = FALSE)
# Save the dataframe nodes to a CSV file for Gephi
write.csv(nodes, "nodes_for_gephi.csv", row.names = FALSE)
```
